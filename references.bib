@article{wang19_kervol_neural_networ,
  author =       {Wang, Chen and Yang, Jianfei and Xie, Lihua and Yuan, Junsong},
  title =        {Kervolutional Neural Networks},
  journal =      {CoRR},
  year =         2019,
  url =          {http://arxiv.org/abs/1904.03955v2},
  abstract =     {Convolutional neural networks (CNNs) have enabled the
                  state-of-the-art performance in many computer vision tasks.
                  However, little effort has been devoted to establishing
                  convolution in non-linear space. Existing works mainly
                  leverage on the activation layers, which can only provide
                  point-wise non-linearity. To solve this problem, a new
                  operation, kervolution (kernel convolution), is introduced to
                  approximate complex behaviors of human perception systems
                  leveraging on the kernel trick. It generalizes convolution,
                  enhances the model capacity, and captures higher order
                  interactions of features, via patch-wise kernel functions, but
                  without introducing additional parameters. Extensive
                  experiments show that kervolutional neural networks (KNN)
                  achieve higher accuracy and faster convergence than baseline
                  CNN.},
  archivePrefix ={arXiv},
  eprint =       {1904.03955},
  primaryClass = {cs.CV},
}

@inproceedings{cui2017kernel,
  title={Kernel pooling for convolutional neural networks},
  author={Cui, Yin and Zhou, Feng and Wang, Jiang and Liu, Xiao and Lin, Yuanqing and Belongie, Serge},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2921--2930},
  year={2017}
}
@inproceedings{yang2015deep,
  title={Deep fried convnets},
  author={Yang, Zichao and Moczulski, Marcin and Denil, Misha and de Freitas, Nando and Smola, Alex and Song, Le and Wang, Ziyu},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={1476--1483},
  year={2015}
}
